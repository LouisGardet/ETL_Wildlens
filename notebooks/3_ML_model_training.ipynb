{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üß† √âTAPE 0 ‚Äî Initialisation du Bloc 2\n",
    "\n",
    "‚û§ Objectif : Charger le dataset final dataset_index.csv g√©n√©r√© au Bloc 1.\n",
    "‚û§ Objectif : V√©rifier qu‚Äôil est exploitable et pr√™t pour le Machine Learning."
   ],
   "id": "f9f9cd1ec535fee4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Charger le dataset final du Bloc 1\n",
    "df = pd.read_csv(\"../data/processed/dataset_index.csv\", sep=\";\")\n",
    "print(f\"{len(df)} fichiers charg√©s\")\n",
    "print(f\"{df['espece'].nunique()} esp√®ces d√©tect√©es\")\n",
    "df.head()"
   ],
   "id": "6a901e90b058bfda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üìä √âTAPE 1 ‚Äî Analyse de la distribution par esp√®ce\n",
    "\n",
    "‚û§ Objectif : V√©rifier l‚Äô√©quilibrage du dataset.\n",
    "‚û§ Objectif : Identifier les classes sous-repr√©sent√©es et pr√©parer la suite du ML.\n",
    "\t‚Ä¢\tCompter le nombre d‚Äôimages par esp√®ce\n",
    "\t‚Ä¢\tVisualiser la distribution avec un barplot\n",
    "\t‚Ä¢\tD√©tecter si certaines esp√®ces sont sous-repr√©sent√©es\n",
    "\t‚Ä¢\tOptionnel : undersampling/oversampling pour √©quilibrer le dataset"
   ],
   "id": "acf36deb75cd2aa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Comptage par esp√®ce\n",
    "counts = df['espece'].value_counts()\n",
    "print(counts)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12,5))\n",
    "counts.plot(kind='bar', title=\"Nombre d'images par esp√®ce\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.show()"
   ],
   "id": "a5d9551e16f4eed0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üñºÔ∏è √âTAPE 2 ‚Äî Pr√©traitement des images\n",
    "\t‚Ä¢\tCharger quelques images pour v√©rifier leur lisibilit√©\n",
    "\t‚Ä¢\tRedimensionner toutes les images √† une taille fixe (ex : 128√ó128)\n",
    "\t‚Ä¢\tConvertir les images en niveaux de gris ou RGB normalis√© [0,1]\n",
    "\t‚Ä¢\tAssocier chaque image √† son label (l‚Äôesp√®ce)\n",
    "\t‚Ä¢\tPr√©parer une structure numpy (X, y) exploitable par l‚ÄôIA"
   ],
   "id": "39bab67d336d322b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Param√®tres du pr√©traitement\n",
    "IMG_SIZE = 128  # Taille cible des images (128x128)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# It√©ration sur le dataset\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    img_path = row['fichier']\n",
    "    label = row['espece']\n",
    "\n",
    "    # Lecture de l'image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue  # Si une image est corrompue ou manquante\n",
    "\n",
    "    # Redimensionnement\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # Normalisation [0,1]\n",
    "    img = img.astype('float32') / 255.0\n",
    "\n",
    "    X.append(img)\n",
    "    y.append(label)\n",
    "\n",
    "# Conversion en numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"Dataset images : {X.shape}\")\n",
    "print(f\"Labels : {y.shape}, classes uniques : {np.unique(y)}\")"
   ],
   "id": "ac587a8d262fdd88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "‚ö° Patch M√©moire ‚Äî Optimisation Mac M2\n",
    "\n",
    "‚û§ Objectif : R√©duire la consommation m√©moire pour √©viter les erreurs PyCharm sur Mac M2.\n",
    "‚û§ Actions :\n",
    "‚Ä¢ Conversion des images en float16 (2√ó moins de m√©moire)\n",
    "‚Ä¢ Lib√©ration des variables temporaires inutiles\n",
    "‚Ä¢ Option : sauvegarde des splits sur disque pour rechargement rapide"
   ],
   "id": "8dc8005bd702739b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "# Conversion en float16 pour r√©duire la m√©moire\n",
    "X = X.astype('float16')\n",
    "\n",
    "# Lib√©ration m√©moire non utilis√©e\n",
    "gc.collect()\n",
    "\n",
    "# Optionnel : sauvegarde des donn√©es pr√©trait√©es\n",
    "np.savez_compressed(\"../data/processed/dataset_float16.npz\", X=X, y=y)\n",
    "print(\"Patch m√©moire appliqu√© : X en float16 et dataset sauvegard√©.\")"
   ],
   "id": "13f538c4139a091f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üìä √âtape suivante : √âTAPE 3 ‚Äî Split du dataset (check-up)\n",
    "\n",
    "Objectifs :\n",
    "\t‚Ä¢\tCr√©er les jeux train / validation / test\n",
    "\t‚Ä¢\tS‚Äôassurer que la r√©partition est stratifi√©e par esp√®ce\n",
    "\t‚Ä¢\tPr√©parer √† l‚Äôentra√Ænement du mod√®le pr√©dictif IA"
   ],
   "id": "9d1edd9a4f525a52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Encodage des labels en entiers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Encodage one-hot pour le mod√®le IA\n",
    "y_onehot = to_categorical(y_encoded)\n",
    "print(f\"y_onehot shape : {y_onehot.shape}\")\n",
    "\n",
    "# Split Train (70%) / Temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_onehot, test_size=0.30, stratify=y_onehot, random_state=42\n",
    ")\n",
    "\n",
    "# Split Temp en Validation (15%) / Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train : {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation : {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test : {X_test.shape}, {y_test.shape}\")"
   ],
   "id": "44ef174291bf6884",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üìä √âTAPE 4 ‚Äî Split du dataset (Train / Validation / Test)\n",
    "\n",
    "Objectifs :\n",
    "\t‚Ä¢\tS√©parer le dataset en train / validation / test (70% / 15% / 15%)\n",
    "\t‚Ä¢\tStratifier par esp√®ce pour respecter les proportions\n",
    "\t‚Ä¢\tV√©rifier la r√©partition des classes visuellement avant l‚Äôentra√Ænement du mod√®le"
   ],
   "id": "7183daacf20869e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1Ô∏è‚É£ Encodage des labels en entiers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# 2Ô∏è‚É£ Encodage one-hot pour le mod√®le IA\n",
    "y_onehot = to_categorical(y_encoded)\n",
    "print(f\"y_onehot shape : {y_onehot.shape}\")\n",
    "\n",
    "# 3Ô∏è‚É£ Split Train (70%) / Temp (30%) avec stratification\n",
    "X_train, X_temp, y_train, y_temp, y_train_enc, y_temp_enc = train_test_split(\n",
    "    X, y_onehot, y_encoded,\n",
    "    test_size=0.30,\n",
    "    stratify=y_encoded,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Split Temp (30%) en Validation (15%) / Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp_enc,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5Ô∏è‚É£ V√©rification des dimensions\n",
    "print(f\"Train : {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation : {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test : {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# 6Ô∏è‚É£ V√©rification de la r√©partition\n",
    "train_counts = np.sum(y_train, axis=0)\n",
    "val_counts   = np.sum(y_val, axis=0)\n",
    "test_counts  = np.sum(y_test, axis=0)\n",
    "\n",
    "print(\"R√©partition des classes (train) :\", train_counts)\n",
    "print(\"R√©partition des classes (val)   :\", val_counts)\n",
    "print(\"R√©partition des classes (test)  :\", test_counts)\n",
    "\n",
    "# 7Ô∏è‚É£ Visualisation de la r√©partition\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 4), sharey=True)\n",
    "classes = le.classes_\n",
    "\n",
    "ax[0].bar(classes, train_counts)\n",
    "ax[0].set_title(\"Train\")\n",
    "ax[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "ax[1].bar(classes, val_counts, color='orange')\n",
    "ax[1].set_title(\"Validation\")\n",
    "ax[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "ax[2].bar(classes, test_counts, color='green')\n",
    "ax[2].set_title(\"Test\")\n",
    "ax[2].tick_params(axis='x', rotation=90)\n",
    "\n",
    "fig.suptitle(\"R√©partition des classes par split\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f99939c8441947a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üìå √âTAPE 4 bis ‚Äî Cr√©ation du mod√®le pr√©dictif avec MobileNetV2\n",
    "\n",
    "Objectifs :\n",
    "\t‚Ä¢\tCharger MobileNetV2 pr√©-entra√Æn√© sur ImageNet sans sa derni√®re couche\n",
    "\t‚Ä¢\tAjouter des couches personnalis√©es pour classer 13 esp√®ces\n",
    "\t‚Ä¢\tGeler une partie du r√©seau pour √©viter l‚Äôoverfitting\n",
    "\t‚Ä¢\tCompiler le mod√®le pr√™t √† l‚Äôentra√Ænement\n"
   ],
   "id": "e1679eefb0817775"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# 1Ô∏è‚É£ Charger MobileNetV2 sans la derni√®re couche\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,          # On enl√®ve la classification ImageNet\n",
    "    input_shape=(128, 128, 3)   # M√™me taille que nos images\n",
    ")\n",
    "\n",
    "# 2Ô∏è‚É£ Freeze des premi√®res couches pour √©viter l'overfitting\n",
    "for layer in base_model.layers[:100]:  # On g√®le ~100 couches\n",
    "    layer.trainable = False\n",
    "\n",
    "# 3Ô∏è‚É£ Ajouter des couches personnalis√©es\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)        # R√©duction dimensionnelle\n",
    "x = Dropout(0.3)(x)                    # Dropout pour r√©gularisation\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# 4Ô∏è‚É£ Cr√©er le mod√®le final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 5Ô∏è‚É£ Compiler le mod√®le\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "id": "a7d9b5110188fd32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üìä √âTAPE 5 ‚Äî Entra√Ænement du mod√®le MobileNetV2\n",
    "\n",
    "Objectifs :\n",
    "\t‚Ä¢\tEntra√Æner le mod√®le sur le jeu d‚Äôentra√Ænement\n",
    "\t‚Ä¢\tSuivre la loss et l‚Äôaccuracy sur validation\n",
    "\t‚Ä¢\tAjouter :\n",
    "\t‚Ä¢\tData Augmentation (rotation, flip horizontal‚Ä¶)\n",
    "\t‚Ä¢\tEarlyStopping (arr√™t si la val_loss stagne)\n",
    "\t‚Ä¢\tModelCheckpoint (sauvegarde du meilleur mod√®le)\n",
    "\t‚Ä¢\tVisualiser les courbes d‚Äôapprentissage √† la fin\n"
   ],
   "id": "251aba51c8addf57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1Ô∏è‚É£ Data Augmentation pour enrichir artificiellement le dataset\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# 2Ô∏è‚É£ Callbacks : EarlyStopping + ModelCheckpoint\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    '../models/mobilenetv2_best.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Entra√Ænement du mod√®le\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=16),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Visualisation des courbes d'apprentissage\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"√âvolution de l'accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"√âvolution de la loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "66cc0de0688d0deb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üìå √âTAPE 5 bis ‚Äî Optimisation de l‚Äôentra√Ænement\n",
    "\n",
    "Objectifs :\n",
    "\t‚Ä¢\tAppliquer Data Augmentation pour enrichir le dataset\n",
    "\t‚Ä¢\tAjouter des callbacks intelligents :\n",
    "\t‚Ä¢\tEarlyStopping pour arr√™ter si la validation ne progresse plus\n",
    "\t‚Ä¢\tModelCheckpoint pour sauvegarder le meilleur mod√®le\n",
    "\t‚Ä¢\tReduceLROnPlateau pour ajuster le learning rate si stagnation\n",
    "\t‚Ä¢\tRelancer l‚Äôentra√Ænement avec ces am√©liorations\n"
   ],
   "id": "955d4969b1623236"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# 1Ô∏è‚É£ Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,  # On √©vite pour empreintes si sens important\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# G√©n√©ration sur le dataset d'entra√Ænement uniquement\n",
    "train_gen = datagen.flow(X_train, y_train, batch_size=16)\n",
    "\n",
    "# 2Ô∏è‚É£ Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='../models/best_model.keras',   # format moderne conseill√©\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss'\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# 3Ô∏è‚É£ R√©-entra√Ænement avec augmentation\n",
    "history_aug = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=40,            # On peut se permettre plus gr√¢ce √† EarlyStopping\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Visualisation des courbes\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_aug.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_aug.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"√âvolution de l'accuracy avec Data Augmentation\")\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_aug.history['loss'], label='Train Loss')\n",
    "plt.plot(history_aug.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"√âvolution de la loss avec Data Augmentation\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "1210d600e6023f04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üîé Analyse rapide des courbes et m√©triques\n",
    "\t1.\tAccuracy\n",
    "\t‚Ä¢\tTrain Accuracy : monte √† ~0.78 (78%)\n",
    "\t‚Ä¢\tVal Accuracy : reste bloqu√©e √† ~0.13 (13%)\n",
    "‚ûú Gros √©cart ‚Üí Overfitting s√©v√®re malgr√© Data Augmentation et EarlyStopping.\n",
    "\t2.\tLoss\n",
    "\t‚Ä¢\tTrain Loss : diminue fortement (~0.73) ‚Üí le mod√®le apprend bien sur train.\n",
    "\t‚Ä¢\tVal Loss : reste haute (~3.26) et ne suit pas ‚Üí le mod√®le ne g√©n√©ralise pas.\n",
    "\t3.\tConclusion\n",
    "\t‚Ä¢\tM√™me avec Data Augmentation et ReduceLROnPlateau, le mod√®le ne g√©n√©ralise pas.\n",
    "\t‚Ä¢\tLa faible Val Accuracy (~13%) correspond √† un hasard complet sur 13 classes ‚Üí il ne parvient pas √† extraire les bonnes features pour la validation.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üí° Causes probables\n",
    "\t1.\tDataset trop petit et d√©s√©quilibr√©\n",
    "\t‚Ä¢\t252 images pour 13 classes ‚Üí ~19 images/classe en moyenne.\n",
    "\t‚Ä¢\tDeep Learning sur MobileNetV2 a besoin de plus de donn√©es.\n",
    "\t2.\tVariabilit√© intra-classe faible\n",
    "\t‚Ä¢\tLes empreintes d‚Äôune m√™me esp√®ce sont trop similaires ‚Üí surapprentissage rapide.\n",
    "\t3.\tClasses difficiles √† distinguer visuellement\n",
    "\t‚Ä¢\tEmpreintes de rat / lapin / √©cureuil tr√®s proches.\n",
    "\t‚Ä¢\tM√™me un MobileNet pr√©-entra√Æn√© sur ImageNet peut avoir du mal.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "‚úÖ Plan d‚Äôaction pour am√©liorer la Val Accuracy\n",
    "\t1.\tAugmenter artificiellement le dataset\n",
    "\t‚Ä¢\tScraping : r√©cup√©rer 50‚Äì100 images suppl√©mentaires par classe.\n",
    "\t‚Ä¢\tRotation / Zoom / Flip / Brightness plus agressifs.\n",
    "\t2.\tFreeze plus de couches MobileNet\n",
    "\t‚Ä¢\tActuellement, tu as gel√© 100 couches ‚Üí peut-√™tre geler tout sauf le head pour r√©duire l‚Äôoverfitting.\n",
    "\t‚Ä¢\tPuis d√©gel progressif (Fine-Tuning) apr√®s quelques epochs.\n",
    "\t3.\tR√©duction de la complexit√© du mod√®le\n",
    "\t‚Ä¢\tEssayer EfficientNetB0 ou MobileNetV2 avec alpha=0.35 ‚Üí moins de param√®tres, donc moins d‚Äôoverfit sur petit dataset.\n",
    "\t4.\tValidation crois√©e (K-Fold)\n",
    "\t‚Ä¢\tAvec si peu de donn√©es, un split classique 70/15/15 est tr√®s sensible.\n",
    "\t‚Ä¢\tK-Fold Cross Validation pourrait mieux refl√©ter la perf r√©elle.\n"
   ],
   "id": "b4d481bc9cd24a0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "üÜï √âTAPE 5 ter ‚Äî Scraping d‚Äôimages pour augmenter le dataset\n",
    "\n",
    "üéØ Objectifs :\n",
    "\t‚Ä¢\tR√©cup√©rer de nouvelles images d‚Äôempreintes pour chaque esp√®ce\n",
    "\t‚Ä¢\tAugmenter la diversit√© du dataset pour am√©liorer la val_accuracy\n",
    "\t‚Ä¢\tAutomatiser le t√©l√©chargement, le tri et l‚Äôint√©gration au pipeline\n",
    "# Nouveau\n",
    "üì• √âTAPE 5‚ÄØter ‚Äî Scraping d‚Äôimages compl√©mentaires + Nettoyage\n",
    "\n",
    "Objectifs :\n",
    "\t‚Ä¢\tScraper automatiquement de nouvelles images pour les esp√®ces sous-repr√©sent√©es.\n",
    "\t‚Ä¢\tSimuler un vrai navigateur pour √©viter les erreurs 400/403.\n",
    "\t‚Ä¢\tFiltrer les images valides et nettoyer les fichiers corrompus.\n",
    "\t‚Ä¢\tPr√©parer le dataset pour la Data Augmentation et le r√©entra√Ænement."
   ],
   "id": "d14401efc7c25654"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1Ô∏è‚É£ Dossiers de travail\n",
    "base_raw = Path(\"../data/raw_scraped\")              # images brutes scrap√©es\n",
    "base_clean = Path(\"../data/Mammif√®res_scraped_clean\")\n",
    "base_trash = Path(\"../data/Mammif√®res_scraped_trash\")\n",
    "base_clean.mkdir(parents=True, exist_ok=True)\n",
    "base_trash.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2Ô∏è‚É£ Charger MobileNetV2 pour extraction de features\n",
    "feature_model = MobileNetV2(weights=\"imagenet\", include_top=False, pooling='avg')\n",
    "\n",
    "def extract_features(img_path, target_size=(128,128)):\n",
    "    \"\"\"Retourne un vecteur de features pour une image\"\"\"\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = feature_model.predict(x, verbose=0)\n",
    "    return features.flatten()\n",
    "\n",
    "# 3Ô∏è‚É£ Pr√©paration des datasets pour entra√Æner un classifieur binaire rapide\n",
    "#    -> On cr√©e manuellement un petit set d'exemples valid√©s\n",
    "valid_examples = []\n",
    "labels = []\n",
    "\n",
    "# Dossier temporaire avec quelques images valid√©es et rejet√©es √† la main\n",
    "manual_valid = Path(\"../data/manual_binary_training\")\n",
    "if not manual_valid.exists():\n",
    "    print(\"‚ö†Ô∏è Pr√©pare quelques images manuelles pour initialiser le classifieur binaire.\")\n",
    "else:\n",
    "    for cls in [\"valid\", \"trash\"]:  # sous-dossiers\n",
    "        for img_file in (manual_valid/cls).glob(\"*\"):\n",
    "            feat = extract_features(img_file)\n",
    "            valid_examples.append(feat)\n",
    "            labels.append(0 if cls==\"valid\" else 1)\n",
    "\n",
    "X = np.array(valid_examples)\n",
    "y = np.array(labels)\n",
    "\n",
    "# 4Ô∏è‚É£ Entra√Ænement d'un classifieur binaire simple\n",
    "clf = LogisticRegression(max_iter=500)\n",
    "clf.fit(X, y)\n",
    "print(\"‚úÖ Classifieur binaire entra√Æn√©.\")\n",
    "\n",
    "# 5Ô∏è‚É£ Filtrage automatique des images scrap√©es\n",
    "index_data = []\n",
    "\n",
    "for specie_dir in base_raw.iterdir():\n",
    "    if not specie_dir.is_dir():\n",
    "        continue\n",
    "    specie = specie_dir.name.lower()\n",
    "\n",
    "    files = sorted(specie_dir.glob(\"*\"))\n",
    "    counter = 1\n",
    "\n",
    "    for img_path in files:\n",
    "        try:\n",
    "            feat = extract_features(img_path)\n",
    "            pred = clf.predict([feat])[0]  # 0=empreinte valide, 1=trash\n",
    "            target_dir = base_clean if pred==0 else base_trash\n",
    "            target_species_dir = target_dir / specie\n",
    "            target_species_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Renommage\n",
    "            new_name = f\"{specie}_{counter:05d}.jpg\"\n",
    "            counter += 1\n",
    "\n",
    "            shutil.copy(img_path, target_species_dir / new_name)\n",
    "\n",
    "            if pred==0:\n",
    "                index_data.append({\n",
    "                    \"fichier\": str(target_species_dir / new_name),\n",
    "                    \"espece\": specie\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {img_path}: {e}\")\n",
    "\n",
    "# 6Ô∏è‚É£ G√©n√©ration de l‚Äôindex CSV\n",
    "df_index = pd.DataFrame(index_data)\n",
    "csv_path = \"../data/metadata/dataset_scraped_index.csv\"\n",
    "df_index.to_csv(csv_path, index=False, sep=\";\")\n",
    "print(f\"‚úÖ Filtrage termin√© : {len(df_index)} images clean\")\n",
    "print(f\"üìÑ Index CSV g√©n√©r√© : {csv_path}\")"
   ],
   "id": "cd45a04c758b907",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
